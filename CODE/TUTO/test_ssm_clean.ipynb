{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle-Based Surface Shape Modeling\n",
    "## PART 1\n",
    "\n",
    "```\n",
    "conda activate shapeworks\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import shapeworks as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.spatial import cKDTree\n",
    "import pyvista as pv\n",
    "import vtk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load shape images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of shapes: 2\n",
      "DATA\\F006_label_4_RF.nii.gz\n",
      "DATA\\F099_label_4_RF.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# PATHS\n",
    "\n",
    "data_path=\"./DATA/\"\n",
    "shapeExtention = '.nii.gz'\n",
    "shapeFilenames = sorted(glob.glob(data_path + '*' + shapeExtention)) \n",
    "\n",
    "print ('Number of shapes: ' + str(len(shapeFilenames)))\n",
    "for shapeFilename in shapeFilenames:\n",
    "    shapeFilename = Path(shapeFilename)\n",
    "    print(shapeFilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./DATA\\F006_label_4_RF.nii.gz\n",
      "Loading: ./DATA\\F099_label_4_RF.nii.gz\n",
      "\n",
      "2 segmentations are loaded for the dataset...\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND DOWNSAMPLE SEGMENTATIONS\n",
    "\n",
    "def downsample_volume(volume, factor):\n",
    "    data = volume.toArray()\n",
    "    zoom_factors = (1 / factor, 1 / factor, 1 / factor)\n",
    "    downsampled_data = zoom(data, zoom_factors, order=1)  # Using linear interpolation\n",
    "    return sw.Image(downsampled_data.astype(np.float32))\n",
    "\n",
    "# Adjust the downsample factor based on your hardware capabilities\n",
    "downsample_factor = 2\n",
    "\n",
    "# List of shape segmentations\n",
    "small_shapes = []\n",
    "\n",
    "# List of shape names (shape files prefixes) to be used for saving outputs and visualizations\n",
    "small_shapeNames = [] \n",
    "\n",
    "# Loop over all shape files and load individual segmentations\n",
    "for shapeFilename in shapeFilenames:\n",
    "    print('Loading: ' + str(shapeFilename))\n",
    "    \n",
    "    # Convert to Path object to access .name attribute\n",
    "    shapeFilename = Path(shapeFilename)\n",
    "    \n",
    "    # Current shape name\n",
    "    segFilename = shapeFilename.name\n",
    "    shapeName = segFilename[:-len(shapeExtention)]\n",
    "    small_shapeNames.append(shapeName)\n",
    "    \n",
    "    # Load segmentation\n",
    "    shapeSeg = sw.Image(str(shapeFilename))\n",
    "    \n",
    "    # Downsample the volume if needed\n",
    "    downsampled_shapeSeg = downsample_volume(shapeSeg, downsample_factor)\n",
    "    \n",
    "    # Append to the shape list\n",
    "    small_shapes.append(downsampled_shapeSeg)\n",
    "\n",
    "num_samples = len(small_shapes)\n",
    "print('\\n' + str(num_samples) + ' segmentations are loaded for the dataset...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#VISUALIZATION PARAMETERS\n",
    "\n",
    "use_same_window = False # plot using multiple rendering windows if false\n",
    "notebook        = False # True will enable the plots to lie inline\n",
    "show_borders    = True  # show borders for each rendering window\n",
    "shade_volumes   = True  # use shading when performing volume rendering\n",
    "color_map       = \"viridis\" # color map for volume rendering, e.g., 'bone', 'coolwarm', 'cool', 'viridis', 'magma'\n",
    "show_axes       = True  # show a vtk axes widget for each rendering window\n",
    "show_bounds     = True  # show volume bounding box\n",
    "show_all_edges  = True  # add an unlabeled and unticked box at the boundaries of plot. \n",
    "font_size       = 10    # text font size for windows\n",
    "link_views      = True  # link all rendering windows so that they share same camera and axes boundaries\n",
    "\n",
    "\n",
    "# EXAMPLE USAGE\n",
    "\n",
    "\"\"\" \n",
    "sw.plot_volumes(small_shapes,    \n",
    "             volumeNames     = small_shapeNames, \n",
    "             use_same_window = use_same_window,\n",
    "             notebook        = notebook,\n",
    "             show_borders    = show_borders,  \n",
    "             shade_volumes   = shade_volumes, \n",
    "             color_map       = color_map,\n",
    "             show_axes       = show_axes,  \n",
    "             show_bounds     = show_bounds,\n",
    "             show_all_edges  = show_all_edges, \n",
    "             font_size       = font_size,   \n",
    "             link_views      = link_views\n",
    "             ) \n",
    "\"\"\"\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape 0 voxel values before binarization: [0.         0.09131903 0.09252457 ... 0.89141685 0.8925598  1.        ]\n",
      "Shape 0 voxel values after binarization: [0. 1.]\n",
      "Shape 1 voxel values before binarization: [0.000000e+00 5.842163e-04 1.215121e-03 ... 9.815617e-01 9.956332e-01\n",
      " 1.000000e+00]\n",
      "Shape 1 voxel values after binarization: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Threshold and binarize the segmentation images\n",
    "for idx in range(len(small_shapes)):\n",
    "    shapeSeg = small_shapes[idx]\n",
    "    # Convert to numpy array to inspect voxel values\n",
    "    shapeSeg_array = shapeSeg.toArray()\n",
    "    # Get unique voxel values\n",
    "    voxelValues = np.unique(shapeSeg_array)\n",
    "    print(f\"Shape {idx} voxel values before binarization: {voxelValues}\")\n",
    "    \n",
    "    # Determine threshold values\n",
    "    minVal = voxelValues.min()\n",
    "    maxVal = voxelValues.max()\n",
    "    threshold = (minVal + maxVal) / 2.0  # Midpoint threshold\n",
    "\n",
    "    # Binarize the image: set voxels >= threshold to 1.0, else 0.0\n",
    "    shapeSeg.binarize(minVal=threshold, maxVal=maxVal, innerVal=1.0, outerVal=0.0)\n",
    "    \n",
    "    # Verify binarization\n",
    "    binarized_voxelValues = np.unique(shapeSeg.toArray())\n",
    "    print(f\"Shape {idx} voxel values after binarization: {binarized_voxelValues}\")\n",
    "    \n",
    "    # Update the image in the list\n",
    "    small_shapes[idx] = shapeSeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapeworks image header information: \n",
      "{\n",
      "\tdims: [233, 226, 759],\n",
      "\torigin: [0, 0, 0],\n",
      "\tsize: [233, 226, 759],\n",
      "\tspacing: [1, 1, 1]\n",
      "}\n",
      "\n",
      "vtk image header information: \n",
      "ImageData (0x19d38816460)\n",
      "  N Cells:      39567600\n",
      "  N Points:     39967422\n",
      "  X Bounds:     0.000e+00, 2.320e+02\n",
      "  Y Bounds:     0.000e+00, 2.250e+02\n",
      "  Z Bounds:     0.000e+00, 7.580e+02\n",
      "  Dimensions:   233, 226, 759\n",
      "  Spacing:      1.000e+00, 1.000e+00, 1.000e+00\n",
      "  N Arrays:     1\n",
      "shapeworks image header information: \n",
      "{\n",
      "\tdims: [230, 223, 772],\n",
      "\torigin: [0, 0, 0],\n",
      "\tsize: [230, 223, 772],\n",
      "\tspacing: [1, 1, 1]\n",
      "}\n",
      "\n",
      "vtk image header information: \n",
      "ImageData (0x19d388164c0)\n",
      "  N Cells:      39196098\n",
      "  N Points:     39595880\n",
      "  X Bounds:     0.000e+00, 2.290e+02\n",
      "  Y Bounds:     0.000e+00, 2.220e+02\n",
      "  Z Bounds:     0.000e+00, 7.710e+02\n",
      "  Dimensions:   230, 223, 772\n",
      "  Spacing:      1.000e+00, 1.000e+00, 1.000e+00\n",
      "  N Arrays:     1\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO VTK IMAGE\n",
    "shapeSeg1 = small_shapes[0]\n",
    "shapeSeg2 = small_shapes[1]\n",
    "shapeSeg1_vtk = sw.sw2vtkImage(shapeSeg1, verbose = True)\n",
    "shapeSeg2_vtk = sw.sw2vtkImage(shapeSeg2, verbose = True)\n",
    "# sw.plot_volumes(shapeSeg1_vtk)\n",
    "# sw.plot_volumes(shapeSeg2_vtk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved VTK mesh to: OUTPUT/shape1.vtk\n",
      "Saved VTK mesh to: OUTPUT/shape2.vtk\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO MESH\n",
    "\n",
    "def convert_plot_save(shapeSeg, output_filename):\n",
    "    print(f'\\nCreating mesh: {output_filename}')\n",
    "    # Convert shapeSeg to numpy array\n",
    "    shapeSeg_array = shapeSeg.toArray()\n",
    "    # Get unique voxel values\n",
    "    voxelValues = np.unique(shapeSeg_array)\n",
    "    # Suppress scientific notation\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print('Voxel values:' + str(voxelValues))\n",
    "    # Display warning\n",
    "    if len(voxelValues) > 2:\n",
    "        print('WARNING: Voxels have more than two distinct values')\n",
    "        print('PLEASE make sure to use binary segmentations')\n",
    "    else:\n",
    "        print('Shape is a binary segmentation')\n",
    "    # Get min and max values\n",
    "    minVal = shapeSeg_array.min()\n",
    "    maxVal = shapeSeg_array.max()\n",
    "    # Compute isovalue\n",
    "    isoValue = (maxVal - minVal) / 2.0\n",
    "    print('isoValue = ' + str(isoValue))\n",
    "    # Extract isosurface\n",
    "    shapeMesh = shapeSeg.toMesh(isovalue=isoValue)\n",
    "    # Convert to VTK format\n",
    "    shapeMesh_vtk = sw.sw2vtkMesh(shapeMesh)\n",
    "    # Plot\n",
    "    sw.plot_meshes([shapeMesh_vtk])\n",
    "    # Convert VTK mesh to PyVista object\n",
    "    pv_mesh = pv.wrap(shapeMesh_vtk)\n",
    "    # Save the VTK mesh\n",
    "    pv_mesh.save(output_filename)\n",
    "    print(f'Saved VTK mesh to: {output_filename}')\n",
    "    \n",
    "def exportMesh(vtk_mesh, output_filename):\n",
    "    pv_mesh = pv.wrap(vtk_mesh)\n",
    "    pv_mesh.save(output_filename)\n",
    "    print(f'Saved VTK mesh to: {output_filename}')\n",
    "    \n",
    "def seg2mesh(shapeSeg):\n",
    "    print(f'\\nCreating mesh...')\n",
    "    # Convert shapeSeg to numpy array\n",
    "    shapeSeg_array = shapeSeg.toArray()\n",
    "    # Get unique voxel values\n",
    "    voxelValues = np.unique(shapeSeg_array)\n",
    "    # Suppress scientific notation\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print('Voxel values:' + str(voxelValues))\n",
    "    # Display warning\n",
    "    if len(voxelValues) > 2:\n",
    "        print('WARNING: Voxels have more than two distinct values')\n",
    "    # Get min and max values\n",
    "    minVal = shapeSeg_array.min()\n",
    "    maxVal = shapeSeg_array.max()\n",
    "    # Compute isovalue\n",
    "    isoValue = (maxVal - minVal) / 2.0\n",
    "    # Extract isosurface\n",
    "    shapeMesh = shapeSeg.toMesh(isovalue=isoValue)\n",
    "    # Convert to VTK format\n",
    "    shapeMesh_vtk = sw.sw2vtkMesh(shapeMesh, verbose = False)\n",
    "    return shapeMesh_vtk\n",
    "\n",
    "# Example usage\n",
    "# convert_plot_save(shapeSeg1, 'shape1.vtk')\n",
    "# convert_plot_save(shapeSeg2, 'shape2.vtk')\n",
    "\n",
    "output_dir = 'OUTPUT'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "exportMesh(shapeSeg1_vtk, output_dir + '/shape1.vtk')\n",
    "exportMesh(shapeSeg2_vtk, output_dir + '/shape2.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Align shapes (Meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect how mutliple segmentation are spatially aligned with respect to each other, we will visualize their surfaces in the same rendering window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating mesh...\n",
      "Voxel values:[0. 1.]\n",
      "\n",
      "Creating mesh...\n",
      "Voxel values:[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# PLOT MESHES\n",
    "\n",
    "shape_iso_surfaces = [seg2mesh(shapeSeg1), seg2mesh(shapeSeg2)]\n",
    "\n",
    "sw.plot_meshes(shape_iso_surfaces,       \n",
    "            use_same_window = True, \n",
    "            notebook        = False,  \n",
    "            show_borders    = True,  \n",
    "            meshes_color    = ['blue','red'], \n",
    "            mesh_style      = \"surface\", \n",
    "            show_mesh_edges = False, \n",
    "            show_axes       = True,  \n",
    "            show_bounds     = True,  \n",
    "            show_all_edges  = True,  \n",
    "            font_size       = 10,    \n",
    "            link_views      = True   \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56994\n",
      "45538\n"
     ]
    }
   ],
   "source": [
    "# CENTER AND SCALE MESHES\n",
    "\n",
    "for mesh in shape_iso_surfaces:\n",
    "    # Get the points of the mesh\n",
    "    points = mesh.points\n",
    "    print(len(points))\n",
    "    # Compute the centroid of the mesh\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    # Center the mesh at the origin\n",
    "    points -=  centroid\n",
    "    # Compute the scale factor (maximum distance from origin)\n",
    "    distances = np.linalg.norm(points, axis=1)\n",
    "    scale_factor = np.max(distances)\n",
    "    # Scale the mesh to unit size\n",
    "    points /= scale_factor\n",
    "    mesh.points = points\n",
    "\n",
    "sw.plot_meshes(\n",
    "    shape_iso_surfaces,\n",
    "    use_same_window=True,\n",
    "    notebook=False,\n",
    "    show_borders=True,\n",
    "    meshes_color=['blue', 'red'],\n",
    "    mesh_style=\"surface\",\n",
    "    show_mesh_edges=False,\n",
    "    show_axes=True,\n",
    "    show_bounds=True,\n",
    "    show_all_edges=True,\n",
    "    font_size=10,\n",
    "    link_views=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting VTK mesh to PyVista mesh...\n",
      "Converting VTK mesh to PyVista mesh...\n",
      "Starting particle-based optimization with 1000 points and 20 iterations...\n",
      "Sampling 1000 random points on the mesh...\n",
      "    Iteration 0/20...\n",
      "    Iteration 10/20...\n",
      "Optimization complete.\n",
      "Starting particle-based optimization with 1000 points and 20 iterations...\n",
      "Sampling 1000 random points on the mesh...\n",
      "    Iteration 0/20...\n",
      "    Iteration 10/20...\n",
      "Optimization complete.\n",
      "Point distributions have been saved.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def vtk_mesh_to_pyvista(mesh):\n",
    "    print(\"Converting VTK mesh to PyVista mesh...\")\n",
    "    # Ensure mesh is a vtkPolyData\n",
    "    if not isinstance(mesh, vtk.vtkPolyData):\n",
    "        raise TypeError(\"Input mesh must be a vtkPolyData\")\n",
    "    # Convert to PyVista mesh\n",
    "    pv_mesh = pv.wrap(mesh)\n",
    "    return pv_mesh\n",
    "\n",
    "pv_meshes = []\n",
    "for sw_mesh in shape_iso_surfaces:\n",
    "    # Convert VTK mesh to PyVista mesh\n",
    "    pv_mesh = vtk_mesh_to_pyvista(sw_mesh)\n",
    "    pv_meshes.append(pv_mesh)\n",
    "\n",
    "def sample_random_points_on_mesh(mesh, n_points):\n",
    "    print(f\"Sampling {n_points} random points on the mesh...\")\n",
    "    # Triangulate the mesh to ensure all faces are triangles\n",
    "    mesh = mesh.triangulate()\n",
    "    # Compute the area of each triangle\n",
    "    mesh_with_areas = mesh.compute_cell_sizes(length=False, area=True, volume=False)\n",
    "    areas = mesh_with_areas['Area']\n",
    "    total_area = np.sum(areas)\n",
    "    # Normalize areas to get probabilities\n",
    "    probabilities = areas / total_area\n",
    "    # Cumulative distribution\n",
    "    cumulative_areas = np.cumsum(probabilities)\n",
    "    # Sample triangle indices according to their area\n",
    "    random_values = np.random.rand(n_points)\n",
    "    triangle_indices = np.searchsorted(cumulative_areas, random_values)\n",
    "    # Sample points within the selected triangles\n",
    "    points = []\n",
    "    for triangle_idx in triangle_indices:\n",
    "        # Get the indices of the triangle's vertices\n",
    "        cell = mesh.faces[triangle_idx * 4:(triangle_idx + 1) * 4]\n",
    "        indices = cell[1:4]\n",
    "        triangle = mesh.points[indices]\n",
    "        # Generate random barycentric coordinates\n",
    "        r1 = np.random.rand()\n",
    "        r2 = np.random.rand()\n",
    "        sqrt_r1 = np.sqrt(r1)\n",
    "        barycentric_coords = [1 - sqrt_r1, sqrt_r1 * (1 - r2), sqrt_r1 * r2]\n",
    "        point = (barycentric_coords[0] * triangle[0] +\n",
    "                 barycentric_coords[1] * triangle[1] +\n",
    "                 barycentric_coords[2] * triangle[2])\n",
    "        points.append(point)\n",
    "    return np.array(points)\n",
    "\n",
    "def particle_based_optimization(mesh, n_points=1000, iterations=20, step_size=0.01):\n",
    "    print(f\"Starting particle-based optimization with {n_points} points and {iterations} iterations...\")\n",
    "    # Initialize particles by sampling random points on the mesh\n",
    "    particles = sample_random_points_on_mesh(mesh, n_points)\n",
    "    # KDTree for efficient nearest neighbor search\n",
    "    tree = cKDTree(mesh.points)\n",
    "    for i in range(iterations):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"    Iteration {i}/{iterations}...\")\n",
    "        # Compute pairwise distances among particles\n",
    "        particle_tree = cKDTree(particles)\n",
    "        pairs = particle_tree.query_pairs(r=0.05)\n",
    "        # Initialize forces\n",
    "        forces = np.zeros_like(particles)\n",
    "        for idx1, idx2 in pairs:\n",
    "            # Compute vector between particles\n",
    "            vec = particles[idx1] - particles[idx2]\n",
    "            dist = np.linalg.norm(vec)\n",
    "            if dist > 1e-5:\n",
    "                # Repulsive force\n",
    "                force = vec / dist**2\n",
    "                forces[idx1] += force\n",
    "                forces[idx2] -= force\n",
    "        # Update particle positions\n",
    "        particles += step_size * forces\n",
    "        # Project back onto the mesh surface\n",
    "        distances, idx = tree.query(particles)\n",
    "        particles = mesh.points[idx]\n",
    "    print(\"Optimization complete.\")\n",
    "    return particles\n",
    "\n",
    "# List to store optimized particle positions for each mesh\n",
    "optimized_points_list = []\n",
    "\n",
    "for mesh in pv_meshes:\n",
    "    optimized_points = particle_based_optimization(mesh)\n",
    "    optimized_points_list.append(optimized_points)\n",
    "\n",
    "# Plot the optimized points on both meshes side by side\n",
    "p = pv.Plotter(shape=(1, 2), notebook=False)\n",
    "\n",
    "# Plot first mesh and its points\n",
    "p.subplot(0, 0)\n",
    "p.add_mesh(pv_meshes[0], color='lightgray', opacity=0.5, show_edges=False)\n",
    "p.add_points(optimized_points_list[0], color='blue', point_size=5)\n",
    "\n",
    "# Plot second mesh and its points\n",
    "p.subplot(0, 1)\n",
    "p.add_mesh(pv_meshes[1], color='lightgray', opacity=0.5, show_edges=False)\n",
    "p.add_points(optimized_points_list[1], color='red', point_size=5)\n",
    "\n",
    "p.show(title='Particle-Based Optimization on Meshes')\n",
    "\n",
    "# Save the optimized points\n",
    "np.save('optimized_points_mesh1.npy', optimized_points_list[0])\n",
    "np.save('optimized_points_mesh2.npy', optimized_points_list[1])\n",
    "\n",
    "print(\"Point distributions have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert VTK mesh to PyVista mesh\n",
    "def vtk_mesh_to_pyvista(mesh):\n",
    "    print(\"Converting VTK mesh to PyVista mesh...\")\n",
    "    if not isinstance(mesh, vtk.vtkPolyData):\n",
    "        raise TypeError(\"Input mesh must be a vtk.vtkPolyData\")\n",
    "    pv_mesh = pv.wrap(mesh)\n",
    "    return pv_mesh\n",
    "\n",
    "# Assuming you have your VTK meshes loaded in 'shape_iso_surfaces'\n",
    "pv_meshes = []\n",
    "optimized_points_list = []\n",
    "\n",
    "# Create a directory for saving the meshes as VTK files\n",
    "mesh_output_dir = \"mesh_files/\"\n",
    "os.makedirs(mesh_output_dir, exist_ok=True)\n",
    "\n",
    "# Convert VTK meshes to PyVista meshes and save them as VTK files\n",
    "mesh_file_paths = []\n",
    "for i, sw_mesh in enumerate(shape_iso_surfaces):\n",
    "    pv_mesh = vtk_mesh_to_pyvista(sw_mesh)\n",
    "    pv_meshes.append(pv_mesh)\n",
    "    \n",
    "    # Save the PyVista mesh as a VTK file\n",
    "    mesh_file_path = os.path.join(mesh_output_dir, f'mesh_{i+1}.vtk')\n",
    "    pv_mesh.save(mesh_file_path)\n",
    "    mesh_file_paths.append(mesh_file_path)\n",
    "\n",
    "# Function to perform particle-based optimization across all meshes\n",
    "def particle_based_optimization_for_all_meshes(mesh_files, number_of_particles=1024):\n",
    "    \"\"\"\n",
    "    Perform particle-based optimization to distribute points on meshes.\n",
    "    Args:\n",
    "        mesh_files: List of paths to mesh files (in .vtk or other supported formats).\n",
    "        number_of_particles: Number of particles (points) to distribute on each mesh.\n",
    "    Returns:\n",
    "        optimized_points_all_meshes: List of optimized points arrays for each mesh.\n",
    "    \"\"\"\n",
    "    # Initialize ShapeWorks ParticleSystem with the list of mesh files\n",
    "    particle_system = sw.ParticleSystem(mesh_files)\n",
    "\n",
    "    # Set optimization parameters\n",
    "    optimization_params = sw.OptimizationParameters()\n",
    "    optimization_params.number_of_particles = number_of_particles\n",
    "    optimization_params.use_normals = 1\n",
    "    optimization_params.normal_weight = 10.0\n",
    "    optimization_params.attributes_per_domain = 0\n",
    "    optimization_params.procrustes_interval = 5\n",
    "    optimization_params.procrustes_scaling = 1\n",
    "    optimization_params.optimization_iterations = 1000\n",
    "    optimization_params.initial_relative_weighting = 0.05\n",
    "    optimization_params.relative_weighting = 0.5\n",
    "    optimization_params.starting_regularization = 1000\n",
    "    optimization_params.ending_regularization = 1.0\n",
    "    optimization_params.recompute_regularization_interval = 1\n",
    "    optimization_params.save_init_splits = 0\n",
    "    optimization_params.domain_type = 0  # 0 for surface, 1 for image\n",
    "\n",
    "    # Run the optimization\n",
    "    particle_system.optimize(optimization_params)\n",
    "\n",
    "    # Retrieve optimized points for each mesh\n",
    "    optimized_points_all_meshes = []\n",
    "    for domain in particle_system.get_domains():\n",
    "        points = domain.get_local_points()\n",
    "        optimized_points_all_meshes.append(points)\n",
    "\n",
    "    return optimized_points_all_meshes\n",
    "\n",
    "# Perform particle optimization across all meshes, ensuring consistency\n",
    "optimized_points_all_meshes = particle_based_optimization_for_all_meshes(\n",
    "    mesh_file_paths,\n",
    "    number_of_particles=512  # Adjust based on your needs\n",
    ")\n",
    "\n",
    "# Plot the optimized points on all meshes side by side with consistent labels\n",
    "p = pv.Plotter(shape=(1, len(pv_meshes)), window_size=(1024, 512))\n",
    "for i, (mesh, points) in enumerate(zip(pv_meshes, optimized_points_all_meshes)):\n",
    "    p.subplot(0, i)\n",
    "    p.add_mesh(mesh, color='lightgray', opacity=0.5)\n",
    "    p.add_points(points, render_points_as_spheres=True, point_size=5, color='red')\n",
    "    # Label each point with its index\n",
    "    for idx, point in enumerate(points):\n",
    "        p.add_point_labels(point.reshape(1, -1), [str(idx+1)], point_size=5, font_size=10, text_color='blue')\n",
    "\n",
    "p.link_views()  # Link the camera views\n",
    "p.show()\n",
    "\n",
    "# Save the optimized points for each mesh\n",
    "output_dir = 'output_points/'  # Ensure this directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for i, optimized_points in enumerate(optimized_points_all_meshes):\n",
    "    np.save(output_dir + f'optimized_points_mesh_{i+1}.npy', optimized_points)\n",
    "\n",
    "print(\"Point distributions for all meshes have been saved.\")\n"
   ]
  },
  {
   "attachments": {
    "{6C469355-D084-48EF-9B7A-42FBF634EFA2}.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![{6C469355-D084-48EF-9B7A-42FBF634EFA2}.png](attachment:{6C469355-D084-48EF-9B7A-42FBF634EFA2}.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapeworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
